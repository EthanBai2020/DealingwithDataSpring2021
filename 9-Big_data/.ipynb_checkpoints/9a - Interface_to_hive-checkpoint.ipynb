{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Big Data and Python\n",
    "\n",
    "Big Data clusters usually offer HIVE as an SQL like interface. This allows end-users who do not know how to write \n",
    "map-reduce code, or PIG ot Java to manipulate files in the HDFS. The way they do this is to treat a folder of files as a table. Each file in the folder has to have the same structure. Typically, the folder contains files which are collected\n",
    "over time, so every minute, hour, day another file is added. Users can then search, filter, join, merge the files using HQL, the HIVE QUERY LANGUAGE.\n",
    "\n",
    "However, many analytical packages support remote access to Relational Data Bases. Examples being SAS, SPSS, R, Tableau, python, ...\n",
    "\n",
    "Hive supports Hive server, which allows remote connections to HIVE, and allows remote execution of HQL commands. This allows a wide range of capabilities for analytical packages to use HIVE to do their back-end processing, and then pull the results to do analysis.\n",
    "\n",
    "We will try to use this to  connect our IPYTHON  notebooks to the Stern big data cluster.\n",
    "\n",
    "But first we need to install some software.\n",
    "We need to install a package called pyhs2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!sudo pip install pyhs2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Oops, didn't work.  We see that it needs something called sasl. Let's try and find it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!sudo apt-cache search sasl\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Let's try libsasl2-2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!sudo apt-get install libsasl2-2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### hmm... It was already installed. Some googling suggests installing the \n",
    "#### development versuion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!sudo apt-get install libsasl2-dev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Let's see if that did the trick...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!sudo pip install pyhs2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  SUCCESS !!\n",
    "\n",
    "##### Now we need to see how to connect to the Stern Bigdata  HIVE server. It runs on port 10000 on bigdata.stern.nyu.edu\n",
    "##### Our hive server doesn't have any authentication, but you have to supply a userid and password anyway.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pyhs2\n",
    " \n",
    "with pyhs2.connect(host='bigdata.stern.nyu.edu',\n",
    "                   port=10000,\n",
    "                   authMechanism=\"PLAIN\",\n",
    "                   user='root',\n",
    "                   password='test',\n",
    "                   database='dealings2016') as conn:\n",
    "    with conn.cursor() as cur:\n",
    "        #Show databases\n",
    "        print cur.getDatabases()\n",
    "        \n",
    "        cur.execute(\"use dealings2016\")\n",
    "    \n",
    " \n",
    "        #Execute query\n",
    "        cur.execute(\"select * from 311calls limit 5\")\n",
    " \n",
    "        #Return column info from query\n",
    "        print cur.getSchema()\n",
    " \n",
    "        #Fetch table results\n",
    "        for i in cur.fetch():\n",
    "            print i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## And there we have it. We can access data in our bigdata server directly from python.\n",
    "### Next we need to see if we can actually pull some data. That will be the next notebook.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
