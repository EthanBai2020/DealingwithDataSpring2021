{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "name": " B-Web_APIs_Old.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nhwhite212/DealingwithDataSpring2021/blob/colab/3-WebAPIs_crawling/B-Web_APIs_Old.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wjVacltKMhNE"
      },
      "source": [
        "## Web API's continued: Face Recognition, Entity Extraction, etc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AcWLh3eRModO"
      },
      "source": [
        "# Unfortunately, the faceplus recognition api is no longer free, but it is still very inexpensive."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2vkojKoNMlTG"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6JxS1UOOMhNH"
      },
      "source": [
        "Now let's try to play with a few APIs that are a bit more complex than the ones that we dealt earlier.\n",
        "\n",
        "## FacePlusPlus API: Face Recognition\n",
        "\n",
        "Let's start with the FacePlusPlus API that allows us to recognize faces. We will call the API through Mashape, which will also allow us to learn about _headers_, which is an additional piece of information that we send to APIs, in addition to parameters. The documentation of Face++ on Mashape can be found at https://market.mashape.com/faceplusplus/faceplusplus-face-detection.\n",
        "\n",
        "We will start by analyzing the image below, which is accessible through this URL: http://graphics8.nytimes.com/newsgraphics/2016/02/01/iowa-hp/dd8cb1e066b52661f94bb2306fc54189f1c3325e/hp-kk-dem-1.jpg"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SGYenclPMhNI"
      },
      "source": [
        "![Image from NY Times](http://graphics8.nytimes.com/newsgraphics/2016/02/01/iowa-hp/dd8cb1e066b52661f94bb2306fc54189f1c3325e/hp-kk-dem-1.jpg)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5W8YQ_GLMhNJ",
        "outputId": "7556ff48-927d-4e02-d93e-f89cf47663cd"
      },
      "source": [
        "import requests\n",
        "import json\n",
        "\n",
        "facepp_url = \"https://faceplusplus-faceplusplus.p.mashape.com/detection/detect\"\n",
        "img_url = \"http://graphics8.nytimes.com/newsgraphics/2016/02/01/iowa-hp/dd8cb1e066b52661f94bb2306fc54189f1c3325e/hp-kk-dem-1.jpg\"\n",
        "\n",
        "headers = {\n",
        "   \"X-Mashape-Key\": \"GV6K1ICRbTmsh81eqtIBt6j9AbAep1VqX5Xjsn99NeApuQLJR5\",\n",
        "  \"Accept\": \"application/json\"\n",
        "}\n",
        "parameters = {\n",
        "    'attributes': 'glass,pose,gender,age,race,smiling',\n",
        "    'url': img_url\n",
        "}\n",
        "\n",
        "data = requests.get(facepp_url, params=parameters, headers=headers, verify=True).json()\n",
        "data\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'message': 'Endpoint/detection/detect does not exist'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6H_S_miTMhNK",
        "outputId": "de28bf28-643d-4509-85fa-97e216d0d666"
      },
      "source": [
        "data.keys()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['message'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "huoNC84GMhNL",
        "outputId": "6ba2973d-f415-4ee3-8d1f-f1476aa50ac2"
      },
      "source": [
        "data['face']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "'face'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-3673052dc05a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'face'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m: 'face'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ktNnQ71SMhNM"
      },
      "source": [
        "# The \"face\" attribute contains a list, and each element of the list is a dictionary\n",
        "len(data[\"face\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kjg1Aw35MhNN"
      },
      "source": [
        "#### Exercise\n",
        "\n",
        "* Print the gender, age, race, and smiling attributes for each face\n",
        "* Do an image search and get an image URL from the Internet, preferably with multiple faces. Repeat the task above for the new image."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-AUnxwmtMhNN"
      },
      "source": [
        "# your code here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GKUAMr-cMhNO"
      },
      "source": [
        "### Interacting with the IBM Watson Natural Language Understanding API; POST vs GET\n",
        "\n",
        "Another useful API, especially when dealing with text, is the [IBM Watson  Natural Language Understanding API](https://www.ibm.com/watson/developercloud/natural-language-understanding/api/v1/#introduction), which offers a variety of text analysis functionalities, such as sentiment analysis, entity extraction, keyword extraction, etc.\n",
        "\n",
        "#### /analyze call\n",
        "\n",
        "We will first start with the `GET /analyze` API call ([documentation](https://www.ibm.com/watson/developercloud/natural-language-understanding/api/v1/#get-analyze)), which takes as input a piece of text, and returns an analysis across various dimensions.\n",
        "\n",
        "The call below gets as input a \"text\" variable, and returns back the sentiment of the text."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I7ggAlp8MhNO"
      },
      "source": [
        "import requests\n",
        "import json\n",
        "\n",
        "def getSentiment(text):\n",
        "    endpoint = \"https://gateway.watsonplatform.net/natural-language-understanding/api/v1/analyze\"\n",
        "\n",
        "    # You can register and get your own credentials\n",
        "    # The ones below have a quota of 1000 calls per day \n",
        "    # and can run out quickly if multiple people use these\n",
        "    username = \"802a033d-ff91-4b02-a6c4-a40703ac1b16\"\n",
        "    password = \"TBWFrRx6xwmc\"\n",
        "\n",
        "    parameters = {\n",
        "        #'features' : 'concepts,categories,emotion,entities,keywords,metadata,relations,semantic_roles,sentiment',\n",
        "        'features': 'emotion,sentiment',\n",
        "        'version' : '2017-02-27',\n",
        "        'text': text,\n",
        "        'language' : 'en',\n",
        "        # url = url_to_analyze, this is an alternative to sending the text\n",
        "    }\n",
        "\n",
        "    resp = requests.get(endpoint, params=parameters, auth=(username, password))\n",
        "    \n",
        "    return resp.json()\n",
        "\n",
        "text = '''\n",
        "This class is challenging, but I love how much I am learning.\n",
        "'''\n",
        "\n",
        "data = getSentiment(text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ImMWv31UMhNQ"
      },
      "source": [
        "data.keys()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kdcW1W4XMhNQ"
      },
      "source": [
        "data['sentiment']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Y51ud8jMhNQ"
      },
      "source": [
        "data['emotion']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2bmn6AZmMhNQ"
      },
      "source": [
        "#### Entities call\n",
        "\n",
        "[Full Documentation of the call](https://www.ibm.com/watson/developercloud/natural-language-understanding/api/v1/#entities)\n",
        "\n",
        "This is a an API call that extracts entities from the text, and also the sentiment and emotion for each of these entities. You will also see that there is the capability of \"normalizing\" each entity, so that two different ways of saying the same thing get mapped to the same entity. So for example, \"President Trump\" and \"Donald Trump\" get mapped to the same Knowledge Graph entity."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U17w9esRMhNQ"
      },
      "source": [
        "import requests\n",
        "import json\n",
        "\n",
        "def processURL(url_to_analyze):\n",
        "    endpoint_watson = \"https://gateway.watsonplatform.net/natural-language-understanding/api/v1/analyze\"\n",
        "    params = {\n",
        "        'version': '2017-02-27',\n",
        "    }\n",
        "    headers = { \n",
        "        'Content-Type': 'application/json',\n",
        "    }\n",
        "    watson_options = {\n",
        "      \"url\": url_to_analyze,\n",
        "      \"features\": {\n",
        "        \"entities\": {\n",
        "          \"sentiment\": True,\n",
        "          \"emotion\": True,\n",
        "          \"limit\": 10\n",
        "        }\n",
        "      }\n",
        "    }\n",
        "    username = \"802a033d-ff91-4b02-a6c4-a40703ac1b16\"\n",
        "    password = \"TBWFrRx6xwmc\"\n",
        "\n",
        "    resp = requests.post(endpoint_watson, data=json.dumps(watson_options), \n",
        "                         headers=headers, params=params, auth=(username, password) )\n",
        "    return resp.json()\n",
        "\n",
        "\n",
        "url_to_analyze = 'http://www.politico.com/story/2017/05/23/infrastructure-transportation-trump-budget-238741'\n",
        "\n",
        "data = processURL(url_to_analyze)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z4v5VbXtMhNR"
      },
      "source": [
        "# Let's see what we get back as top-level attributes\n",
        "data.keys()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U2_6dQJbMhNR"
      },
      "source": [
        "# Let' see the entities list\n",
        "data[\"entities\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ojRxe_eMhNS"
      },
      "source": [
        "# Let' see the first entity. Notice the \"disambiguated\" attribute that\n",
        "# points to \"canonical\" versions of the entity, in DBPedia, Freebase, OpenCYC, YAGO, etc\n",
        "data[\"entities\"][0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "emUIRkoUMhNS"
      },
      "source": [
        "# This function takes as input the result\n",
        "# from the IBM Watson API and returns a list\n",
        "# of entities that are relevant (above threshold)\n",
        "# to the article\n",
        "def getEntities(data, threshold):\n",
        "    result = []\n",
        "    for entity in data[\"entities\"]:\n",
        "        relevance = float(entity['relevance'])\n",
        "        if relevance > threshold:\n",
        "            result.append(entity['text'])\n",
        "    return result\n",
        "\n",
        "getEntities(data, 0.25)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "HeAAx3kOMhNS"
      },
      "source": [
        "#### Exercise\n",
        "\n",
        "* Fetch the main page of NY Times. Print the entities that are currently being discussed in the news, together with their relevance value and the associated sentiment.\n",
        "* _Optional:_ Use the NY Times API to fetch the Top Stories News. You can register and get an API key at https://developer.nytimes.com/. The `Top Stories V2 API` provides the details of the news of the day: (The API call documentation is at https://developer.nytimes.com/top_stories_v2.json and the API Call is  https://api.nytimes.com/svc/topstories/v2/home.json?api-key=PUTYOURKEYHERE). Repeat the entity extraction process from above."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LBFfkTtIMhNS"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "eclcjtOLMhNT"
      },
      "source": [
        "### Exercise: Using the Spotify API\n",
        "\n",
        "We will now use the Spotify API to get information about an artist. The documentation of the calls is at https://developer.spotify.com/web-api/endpoint-reference/. For now, use only the calls that do not require an OAuth authentication. \n",
        "\n",
        "Tasks:\n",
        "* We can first find the id of an artist using the `/v1/search?type=artist` API call. The documentation of the `search-item` endpoint is at https://developer.spotify.com/web-api/search-item/.\n",
        "* Once you get back the ID of the artist, use the `get artist` endpoint, to get further information about the artist: https://developer.spotify.com/web-api/get-artist/\n",
        "* Study the documentation and figure out how to get the albums of an article, the top tracks for an artist, and the related artists.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NLvkTn-qMhNT"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}